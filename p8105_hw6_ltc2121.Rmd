---
title: "p8105_hw6_ltc2121"
author: Lindsey Covell
output: github_document
---

```{r, include = FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(labelled)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 

## Problem 2 

#### Data import and manipulation 
```{r}
washp_df = 
  read_csv("data/homicide-data copy.csv") %>% 
  filter(victim_race %in% c("White", "Black")) %>% 
  mutate(city_state = str_c(city, state, sep = ", "),
         resolved = as.numeric(disposition == "Closed by arrest"),
          victim_age = as.numeric(victim_age),
          victim_race = fct_relevel(victim_race, "White"))  %>% 
  filter(city != "Dallas" & city != "Phoenix" & 
           city != "Kansas City" & city_state != "Tulsa, AL") 
```

#### Baltimore, MD glm

```{r}
balti_log = 
  washp_df %>% 
  filter(city == "Baltimore") %>%
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate), 
         CI_low = exp(estimate - 1.96 * std.error), 
         CI_high = exp(estimate + 1.96 * std.error)) %>%
  filter(term == "victim_sexMale") %>% 
  select(term, OR, CI_low, CI_high) 

balti_log %>% 
  knitr::kable(digits = 3)
```

The table above shows the odds of a homicide with a male victim being solved compared to a homicide with a female victim keeping all other variables fixed for Baltimore, MD. 

#### All cities glm

```{r}
wash_logit = 
  washp_df %>% 
  select(city_state, resolved, victim_age, victim_race, victim_sex) %>% 
  nest(data = resolved:victim_sex) %>% 
  mutate(
    city_logs = map(.x = data, ~glm(resolved ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
  city_res = map(city_logs, broom::tidy)) %>% 
  unnest(city_res) %>% 
  mutate(OR = exp(estimate), 
         CI_low = exp(estimate - 1.96 * std.error), 
         CI_high = exp(estimate + 1.96 * std.error)) %>%
  filter(term == "victim_sexMale") %>% 
  select(city_state, term, OR, CI_low, CI_high) 

wash_logit %>% 
  knitr::kable(digits = 3)
  
```

#### Box plot for city estimates 

```{r}
wash_logit %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
ggplot() +
  geom_point(aes(x = city_state, y = OR)) +
  geom_errorbar( aes(x = city_state, ymin = OR - CI_low, ymax = OR + CI_high)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 6)) +
   labs(
    title = "Odds of Homicide Being Solved", 
    subtitle = "Male Victims Compared to Female Victims",
    x = "US City",
    y = "Odds Ratio")
```

The graph shows the odds ratio of a homicide being solved with a male victim compared to a homicide with a female victim while keeping all other variables fixed across numerous US cities. An odds ratio of less than 1 means that homicides in which the victim is male are less like to be resolved than those in which the victim is female. A majority of the cities analyzed and shown in the graph have an odd ratio less than 1. This indicates that a majority of the cities have homicides in which the victim is male are less like to be resolved than those in which the victim is female

## Problem 3

#### Data import and manipulation 
```{r}
birth_wt = 
  read_csv("data/birthweight.csv") %>% 
  set_value_labels(babysex = c("male" = 1, "female" = 2),
                   frace = c("White" = 1, "Black" = 2, "Asain" = 3, "Puerto Rican" = 4, "Other" = 8, "Unknown" = 9), 
                   malform = c("absent" = 0, "present" = 1), 
                   mrace = c("White" = 1, "Black" = 2, "Asain" = 3, "Puerto Rican" = 4, "Other" = 8)) %>%
  mutate_if(is.labelled, to_factor)
  
```

#### Proposed model 

```{r}
mod_1_bw = 
  birth_wt %>% 
  lm(bwt ~ smoken + wtgain + babysex + gaweeks + momage + mrace, data = .) 

mod_1_bw %>% 
  broom::tidy() %>% 
    knitr::kable(digits = 3)
```

#### Diagnostic visual

```{r}
birth_wt %>% 
  add_predictions(mod_1_bw) %>% 
  add_residuals(mod_1_bw) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.5) + 
  geom_smooth(method = lm ) +
   labs(
    title = "Redisuals against Fitted Values",
    x = "Fitted Predictions",
    y = "Residuals") 
```

I proposed the built model off of several factors that have been used in previous literature to show an impact infant birth weight. This includes smoking status during pregnancy, infant biological sex, maternal race, and maternal age. Other factors that I hypothesized would have an impact include gestational age in weeks and mothers weight gain during pregnancy. 

The model is supported with the diagnostic plot which shows the residuals plotted against the fitted values. This plot shows that the spread of residuals is generally consistent across the fitted values. There are a few outlines on each side which could be further investigated with quantitative residual testing. 

#### Model comparison 
```{r}
cv_df = 
  crossv_mc(birth_wt, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
  ) %>% 
  mutate(
    mod_1 = map(.x = train, ~lm(bwt ~ smoken + wtgain + babysex + gaweeks + momage + mrace, data = .)),
    mod_2 =    map(.x = train, ~lm(bwt ~ gaweeks + blength, data = .)),
    mod_3 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead * babysex + bhead * blength + babysex * blength + bhead * blength * babysex, data = .))
  ) %>% 
  mutate(
    rmse_mod1 = map2_dbl(.x = mod_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_mod2 = map2_dbl(.x = mod_2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_mod3 = map2_dbl(.x = mod_3, .y = test, ~rmse(model = .x, data = .y))
  )
```

#### Cross validation results 

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot() +
   labs(
    title = "Cross Validation Results",
    x = "Candidate Models",
    y = "RMSE values") 
```

The cross validation results show that model 3 has the lowest RMSE values which means it has the lowest prediction error. Therefore, compared to model 1 and model 2, the model with the best fit based on prediction accuracy is model 3. This model used the predictors head circumference, length at birth, sex, and all interactions (including the three-way interaction). 
 
